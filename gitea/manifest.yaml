---
# Source: gitea/charts/postgresql/templates/primary/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: gitea-postgresql
  namespace: "gitea"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.3.0
    helm.sh/chart: postgresql-15.5.20
    app.kubernetes.io/component: primary
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: gitea
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    - ports:
        - port: 5432
---
# Source: gitea/charts/redis/templates/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: gitea-redis
  namespace: "gitea"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.5
    helm.sh/chart: redis-19.6.4
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: gitea
      app.kubernetes.io/name: redis
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    # Allow inbound connections
    - ports:
        - port: 6379
---
# Source: gitea/charts/postgresql/templates/primary/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: gitea-postgresql
  namespace: "gitea"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.3.0
    helm.sh/chart: postgresql-15.5.20
    app.kubernetes.io/component: primary
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: gitea
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
---
# Source: gitea/charts/redis/templates/master/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: gitea-redis-master
  namespace: "gitea"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.5
    helm.sh/chart: redis-19.6.4
    app.kubernetes.io/component: master
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: gitea
      app.kubernetes.io/name: redis
      app.kubernetes.io/component: master
---
# Source: gitea/charts/postgresql/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: gitea-postgresql
  namespace: "gitea"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.3.0
    helm.sh/chart: postgresql-15.5.20
automountServiceAccountToken: false
---
# Source: gitea/charts/redis/templates/master/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: false
metadata:
  name: gitea-redis-master
  namespace: "gitea"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.5
    helm.sh/chart: redis-19.6.4
---
# Source: gitea/templates/gitea/act_runner/serviceaccount-job.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: gitea-actions-token-job
  namespace: gitea
  labels:
    helm.sh/chart: gitea-10.6.0
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/version: "1.22.3"
    version: "1.22.3"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: token-job
---
# Source: gitea/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: gitea-postgresql
  namespace: "gitea"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.3.0
    helm.sh/chart: postgresql-15.5.20
type: Opaque
data:
  postgres-password: "SmJYYkZVaVVzOQ=="
  password: "Z2l0ZWE="
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: gitea/charts/redis/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: gitea-redis
  namespace: "gitea"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.5
    helm.sh/chart: redis-19.6.4
type: Opaque
data:
  redis-password: "Y2hhbmdlbWU="
---
# Source: gitea/templates/gitea/act_runner/secret-token.yaml
apiVersion: v1
kind: Secret
metadata:
  name: gitea-actions-token
  labels:
    helm.sh/chart: gitea-10.6.0
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/version: "1.22.3"
    version: "1.22.3"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: token-job
  namespace: gitea
---
# Source: gitea/templates/gitea/config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: gitea-inline-config
  namespace: gitea
  labels:
    helm.sh/chart: gitea-10.6.0
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/version: "1.22.3"
    version: "1.22.3"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  _generals_: ""
  actions: ENABLED=true
  cache: |-
    ADAPTER=redis
    HOST=redis://:changeme@gitea-redis-headless.gitea.svc.cluster.local:6379/0?pool_size=100&idle_timeout=180s&
  database: |-
    DB_TYPE=postgres
    HOST=gitea-postgresql.gitea.svc.cluster.local:5432
    NAME=gitea
    PASSWD=gitea
    USER=gitea
  indexer: |-
    ISSUE_INDEXER_TYPE=bleve
    REPO_INDEXER_ENABLED=true
  metrics: ENABLED=false
  queue: |-
    CONN_STR=redis://:changeme@gitea-redis-headless.gitea.svc.cluster.local:6379/0?pool_size=100&idle_timeout=180s&
    TYPE=redis
  repository: ROOT=/data/git/gitea-repositories
  security: INSTALL_LOCK=true
  server: |-
    APP_DATA_PATH=/data
    DOMAIN=git.example.com
    ENABLE_PPROF=false
    HTTP_PORT=3000
    LOCAL_ROOT_URL=http://gitea-http:3000
    PROTOCOL=http
    ROOT_URL=http://git.example.com
    SSH_DOMAIN=git.example.com
    SSH_LISTEN_PORT=2222
    SSH_PORT=22
    START_SSH_SERVER=true
  session: |-
    PROVIDER=redis
    PROVIDER_CONFIG=redis://:changeme@gitea-redis-headless.gitea.svc.cluster.local:6379/0?pool_size=100&idle_timeout=180s&
---
# Source: gitea/templates/gitea/config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: gitea
  namespace: gitea
  labels:
    helm.sh/chart: gitea-10.6.0
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/version: "1.22.3"
    version: "1.22.3"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  assertions: |
  config_environment.sh: |-
    #!/usr/bin/env bash
    set -euo pipefail

    function env2ini::log() {
      printf "${1}\n"
    }

    function env2ini::read_config_to_env() {
      local section="${1}"
      local line="${2}"

      if [[ -z "${line}" ]]; then
        # skip empty line
        return
      fi
      
      # 'xargs echo -n' trims all leading/trailing whitespaces and a trailing new line
      local setting="$(awk -F '=' '{print $1}' <<< "${line}" | xargs echo -n)"

      if [[ -z "${setting}" ]]; then
        env2ini::log '  ! invalid setting'
        exit 1
      fi

      local value=''
      local regex="^${setting}(\s*)=(\s*)(.*)"
      if [[ $line =~ $regex ]]; then
        value="${BASH_REMATCH[3]}"
      else
        env2ini::log '  ! invalid setting'
        exit 1
      fi

      env2ini::log "    + '${setting}'"

      if [[ -z "${section}" ]]; then
        export "GITEA____${setting^^}=${value}"                           # '^^' makes the variable content uppercase
        return
      fi

      local masked_section="${section//./_0X2E_}"                            # '//' instructs to replace all matches
      masked_section="${masked_section//-/_0X2D_}"

      export "GITEA__${masked_section^^}__${setting^^}=${value}"        # '^^' makes the variable content uppercase
    }

    function env2ini::reload_preset_envs() {
      env2ini::log "Reloading preset envs..."

      while read -r line; do
        if [[ -z "${line}" ]]; then
          # skip empty line
          return
        fi

        # 'xargs echo -n' trims all leading/trailing whitespaces and a trailing new line
        local setting="$(awk -F '=' '{print $1}' <<< "${line}" | xargs echo -n)"

        if [[ -z "${setting}" ]]; then
          env2ini::log '  ! invalid setting'
          exit 1
        fi

        local value=''
        local regex="^${setting}(\s*)=(\s*)(.*)"
        if [[ $line =~ $regex ]]; then
          value="${BASH_REMATCH[3]}"
        else
          env2ini::log '  ! invalid setting'
          exit 1
        fi

        env2ini::log "  + '${setting}'"

        export "${setting^^}=${value}"                           # '^^' makes the variable content uppercase
      done < "/tmp/existing-envs"

      rm /tmp/existing-envs
    }


    function env2ini::process_config_file() {
      local config_file="${1}"
      local section="$(basename "${config_file}")"

      if [[ $section == '_generals_' ]]; then
        env2ini::log "  [ini root]"
        section=''
      else
        env2ini::log "  ${section}"
      fi

      while read -r line; do
        env2ini::read_config_to_env "${section}" "${line}"
      done < <(awk 1 "${config_file}")                             # Helm .toYaml trims the trailing new line which breaks line processing; awk 1 ... adds it back while reading
    }

    function env2ini::load_config_sources() {
      local path="${1}"

      if [[ -d "${path}" ]]; then
        env2ini::log "Processing $(basename "${path}")..."

        while read -d '' configFile; do
          env2ini::process_config_file "${configFile}"
        done < <(find "${path}" -type l -not -name '..data' -print0)

        env2ini::log "\n"
      fi
    }

    function env2ini::generate_initial_secrets() {
      # These environment variables will either be
      #   - overwritten with user defined values,
      #   - initially used to set up Gitea
      # Anyway, they won't harm existing app.ini files

      export GITEA__SECURITY__INTERNAL_TOKEN=$(gitea generate secret INTERNAL_TOKEN)
      export GITEA__SECURITY__SECRET_KEY=$(gitea generate secret SECRET_KEY)
      export GITEA__OAUTH2__JWT_SECRET=$(gitea generate secret JWT_SECRET)
      export GITEA__SERVER__LFS_JWT_SECRET=$(gitea generate secret LFS_JWT_SECRET)

      env2ini::log "...Initial secrets generated\n"
    }
    
    # save existing envs prior to script execution. Necessary to keep order of preexisting and custom envs
    env | (grep -e '^GITEA__' || [[ $? == 1 ]]) > /tmp/existing-envs
    
    # MUST BE CALLED BEFORE OTHER CONFIGURATION
    env2ini::generate_initial_secrets

    env2ini::load_config_sources '/env-to-ini-mounts/inlines/'
    env2ini::load_config_sources '/env-to-ini-mounts/additionals/'

    # load existing envs to override auto generated envs
    env2ini::reload_preset_envs

    env2ini::log "=== All configuration sources loaded ===\n"

    # safety to prevent rewrite of secret keys if an app.ini already exists
    if [ -f ${GITEA_APP_INI} ]; then
      env2ini::log 'An app.ini file already exists. To prevent overwriting secret keys, these settings are dropped and remain unchanged:'
      env2ini::log '  - security.INTERNAL_TOKEN'
      env2ini::log '  - security.SECRET_KEY'
      env2ini::log '  - oauth2.JWT_SECRET'
      env2ini::log '  - server.LFS_JWT_SECRET'

      unset GITEA__SECURITY__INTERNAL_TOKEN
      unset GITEA__SECURITY__SECRET_KEY
      unset GITEA__OAUTH2__JWT_SECRET
      unset GITEA__SERVER__LFS_JWT_SECRET
    fi

    environment-to-ini -o $GITEA_APP_INI
---
# Source: gitea/templates/gitea/init.yaml
apiVersion: v1
kind: Secret
metadata:
  name: gitea-init
  namespace: gitea
  labels:
    helm.sh/chart: gitea-10.6.0
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/version: "1.22.3"
    version: "1.22.3"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  configure_gpg_environment.sh: |-
    #!/usr/bin/env bash
    set -eu

    gpg --batch --import /raw/private.asc
  init_directory_structure.sh: |-
    #!/usr/bin/env bash

    set -euo pipefail
    mkdir -pv /data/git/.ssh
    chmod -Rv 700 /data/git/.ssh
    [ ! -d /data/gitea/conf ] && mkdir -pv /data/gitea/conf

    # prepare temp directory structure
    mkdir -pv "${GITEA_TEMP}"
    chmod -v ug+rwx "${GITEA_TEMP}"

    

  configure_gitea.sh: |-
    #!/usr/bin/env bash

    set -euo pipefail

    echo '==== BEGIN GITEA CONFIGURATION ===='

    { # try
      gitea migrate
    } || { # catch
      echo "Gitea migrate might fail due to database connection...This init-container will try again in a few seconds"
      exit 1
    }
    function test_redis_connection() {
      local RETRY=0
      local MAX=30
      
      echo 'Wait for redis to become avialable...'
      until [ "${RETRY}" -ge "${MAX}" ]; do
        nc -vz -w2 gitea-redis-headless.gitea.svc.cluster.local 6379 && break
        RETRY=$[${RETRY}+1]
        echo "...not ready yet (${RETRY}/${MAX})"
      done

      if [ "${RETRY}" -ge "${MAX}" ]; then
        echo "Redis not reachable after '${MAX}' attempts!"
        exit 1
      fi
    }

    test_redis_connection
    function configure_admin_user() {
      local full_admin_list=$(gitea admin user list --admin)
      local actual_user_table=''

      # We might have distorted output due to warning logs, so we have to detect the actual user table by its headline and trim output above that line
      local regex="(.*)(ID\s+Username\s+Email\s+IsActive.*)"
      if [[ "${full_admin_list}" =~ $regex ]]; then
        actual_user_table=$(echo "${BASH_REMATCH[2]}" | tail -n+2) # tail'ing to drop the table headline
      else
        # This code block should never be reached, as long as the output table header remains the same.
        # If this code block is reached, the regex doesn't match anymore and we probably have to adjust this script.

        echo "ERROR: 'configure_admin_user' was not able to determine the current list of admin users."
        echo "       Please review the output of 'gitea admin user list --admin' shown below."
        echo "       If you think it is an issue with the Helm Chart provisioning, file an issue at https://gitea.com/gitea/helm-chart/issues."
        echo "DEBUG: Output of 'gitea admin user list --admin'"
        echo "--"
        echo "${full_admin_list}"
        echo "--"
        exit 1
      fi

      local ACCOUNT_ID=$(echo "${actual_user_table}" | grep -E "\s+${GITEA_ADMIN_USERNAME}\s+" | awk -F " " "{printf \$1}")
      if [[ -z "${ACCOUNT_ID}" ]]; then
        local -a create_args
        create_args=(--admin --username "${GITEA_ADMIN_USERNAME}" --password "${GITEA_ADMIN_PASSWORD}" --email "suzzz428@gmail.com")
        if [[ "${GITEA_ADMIN_PASSWORD_MODE}" = initialOnlyRequireReset ]]; then
          create_args+=(--must-change-password=true)
        else
          create_args+=(--must-change-password=false)
        fi
        echo "No admin user '${GITEA_ADMIN_USERNAME}' found. Creating now..."
        gitea admin user create "${create_args[@]}"
        echo '...created.'
      else
        if [[ "${GITEA_ADMIN_PASSWORD_MODE}" = keepUpdated ]]; then
          echo "Admin account '${GITEA_ADMIN_USERNAME}' already exist. Running update to sync password..."
          # See https://gitea.com/gitea/helm-chart/issues/673
          # --must-change-password argument was added to change-password, defaulting to true, counter to the previous behavior
          #   which acted as if it were provided with =false. If the argument is present in this version of gitea, then we
          #   should add it to prevent requiring frequent admin password resets.
          local -a change_args
          change_args=(--username "${GITEA_ADMIN_USERNAME}" --password "${GITEA_ADMIN_PASSWORD}")
          if gitea admin user change-password --help | grep -qF -- '--must-change-password'; then
            change_args+=(--must-change-password=false)
          fi
          gitea admin user change-password "${change_args[@]}"
          echo '...password sync done.'
        else
          echo "Admin account '${GITEA_ADMIN_USERNAME}' already exist, but update mode is set to '${GITEA_ADMIN_PASSWORD_MODE}'. Skipping."
        fi
      fi
    }

    configure_admin_user

    function configure_ldap() {
        echo 'no ldap configuration... skipping.'
    }

    configure_ldap

    function configure_oauth() {
        echo 'no oauth configuration... skipping.'
    }

    configure_oauth

    echo '==== END GITEA CONFIGURATION ===='
---
# Source: gitea/charts/redis/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: gitea-redis-configuration
  namespace: "gitea"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.5
    helm.sh/chart: redis-19.6.4
data:
  redis.conf: |-
    # User-supplied common configuration:
    # Enable AOF https://redis.io/topics/persistence#append-only-file
    appendonly yes
    # Disable RDB persistence, AOF persistence already enabled.
    save ""
    # End of common configuration
  master.conf: |-
    dir /data
    # User-supplied master configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of master configuration
  replica.conf: |-
    dir /data
    # User-supplied replica configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of replica configuration
---
# Source: gitea/charts/redis/templates/health-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: gitea-redis-health
  namespace: "gitea"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.5
    helm.sh/chart: redis-19.6.4
data:
  ping_readiness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ] && [ "$responseFirstWord" != "MASTERDOWN" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_readiness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_readiness_master.sh" $1 || exit_status=$?
    exit $exit_status
  ping_liveness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_liveness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_liveness_master.sh" $1 || exit_status=$?
    exit $exit_status
---
# Source: gitea/charts/redis/templates/scripts-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: gitea-redis-scripts
  namespace: "gitea"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.5
    helm.sh/chart: redis-19.6.4
data:
  start-master.sh: |
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    if [[ -f /opt/bitnami/redis/mounted-etc/master.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/master.conf /opt/bitnami/redis/etc/master.conf
    fi
    if [[ -f /opt/bitnami/redis/mounted-etc/redis.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
    fi
    ARGS=("--port" "${REDIS_PORT}")
    ARGS+=("--requirepass" "${REDIS_PASSWORD}")
    ARGS+=("--masterauth" "${REDIS_PASSWORD}")
    ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
    ARGS+=("--include" "/opt/bitnami/redis/etc/master.conf")
    exec redis-server "${ARGS[@]}"
---
# Source: gitea/templates/gitea/act_runner/config-act-runner.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: gitea-act-runner-config
  labels:
    helm.sh/chart: gitea-10.6.0
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/version: "1.22.3"
    version: "1.22.3"
    app.kubernetes.io/managed-by: Helm
  namespace: gitea
data:
  config.yaml: |
    log:
      level: debug
    cache:
      enabled: false
    runner:
      labels:
        - "ubuntu-docker:docker://catthehacker/ubuntu:act-latest"
    container:
      valid_volumes:
        - /var/run/docker.sock
        - /etc/docker/daemon.json
  daemon.json: |
    { "insecure-registries":["192.168.1.249:5000"] }
---
# Source: gitea/templates/gitea/act_runner/config-scripts.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: gitea-scripts
  labels:
    helm.sh/chart: gitea-10.6.0
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/version: "1.22.3"
    version: "1.22.3"
    app.kubernetes.io/managed-by: Helm
  namespace: gitea
data:
  token.sh: |
    #!/bin/sh
  
    set -eu
  
    timeout_delay=15
  
    check_token() {
      set +e
  
      echo "Checking for existing token..."
      token="$(kubectl get secret "$SECRET_NAME" -o jsonpath="{.data['token']}" 2> /dev/null)"
      [ $? -ne 0 ] && return 1
      [ -z "$token" ] && return 2
      return 0
    }
  
    create_token() {
      echo "Waiting for new token to be generated..."
      begin=$(date +%s)
      end=$((begin + timeout_delay))
      while true; do
        [ -f /data/actions/token ] && return 0
        [ "$(date +%s)" -gt $end ] && return 1
        sleep 5
      done
    }
  
    store_token() {
      echo "Storing the token in Kubernetes secret..."
      kubectl patch secret "$SECRET_NAME" -p "{\"data\":{\"token\":\"$(base64 /data/actions/token | tr -d '\n')\"}}"
    }
  
    if check_token; then
      echo "Key already in place, exiting."
      exit
    fi
  
    if ! create_token; then
      echo "Checking for an existing act runner token in secret $SECRET_NAME timed out after $timeout_delay"
      exit 1
    fi
  
    store_token
---
# Source: gitea/templates/gitea/act_runner/role-job.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: gitea-actions-token-job
  labels:
    helm.sh/chart: gitea-10.6.0
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/version: "1.22.3"
    version: "1.22.3"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: token-job
  namespace: gitea
rules:
  - apiGroups:
      - ""
    resources:
      - secrets
    resourceNames:
      - gitea-actions-token
    verbs:
      - get
      - update
      - patch
---
# Source: gitea/templates/gitea/act_runner/rolebinding-job.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: gitea-actions-token-job
  labels:
    helm.sh/chart: gitea-10.6.0
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/version: "1.22.3"
    version: "1.22.3"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: token-job
  namespace: gitea
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: gitea-actions-token-job
subjects:
  - kind: ServiceAccount
    name: gitea-actions-token-job
    namespace: gitea
---
# Source: gitea/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: gitea-postgresql-hl
  namespace: "gitea"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.3.0
    helm.sh/chart: postgresql-15.5.20
    app.kubernetes.io/component: primary
  annotations:
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: gitea/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: gitea-postgresql
  namespace: "gitea"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.3.0
    helm.sh/chart: postgresql-15.5.20
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: gitea/charts/redis/templates/headless-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: gitea-redis-headless
  namespace: "gitea"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.5
    helm.sh/chart: redis-19.6.4
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
  selector:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/name: redis
---
# Source: gitea/charts/redis/templates/master/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: gitea-redis-master
  namespace: "gitea"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.5
    helm.sh/chart: redis-19.6.4
    app.kubernetes.io/component: master
spec:
  type: ClusterIP
  internalTrafficPolicy: Cluster
  sessionAffinity: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
      nodePort: null
  selector:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/name: redis
    app.kubernetes.io/component: master
---
# Source: gitea/templates/gitea/http-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: gitea-http
  namespace: gitea
  labels:
    helm.sh/chart: gitea-10.6.0
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/version: "1.22.3"
    version: "1.22.3"
    app.kubernetes.io/managed-by: Helm
  annotations:
    {}
spec:
  # type: ClusterIP
  type: LoadBalancer
  # clusterIP: None
  ports:
  - name: http
    port: 3000
    targetPort: 
  selector:
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
---
# Source: gitea/templates/gitea/ssh-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: gitea-ssh
  namespace: gitea
  labels:
    helm.sh/chart: gitea-10.6.0
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/version: "1.22.3"
    version: "1.22.3"
    app.kubernetes.io/managed-by: Helm
  annotations:
    {}
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - name: ssh
    port: 22
    targetPort: 2222
    protocol: TCP
  selector:
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
---
# Source: gitea/templates/gitea/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: gitea
  namespace: gitea
  annotations:
  labels:
    helm.sh/chart: gitea-10.6.0
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/version: "1.22.3"
    version: "1.22.3"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0
      maxSurge: 100%
  selector:
    matchLabels:
      app.kubernetes.io/name: gitea
      app.kubernetes.io/instance: gitea
  template:
    metadata:
      annotations:
        checksum/config: 0d463531e6faf405ddf1fce433925142109e88e4036c93974f5a7e26512f6f14
      labels:
        helm.sh/chart: gitea-10.6.0
        app: gitea
        app.kubernetes.io/name: gitea
        app.kubernetes.io/instance: gitea
        app.kubernetes.io/version: "1.22.3"
        version: "1.22.3"
        app.kubernetes.io/managed-by: Helm
    spec:
      
      securityContext:
        fsGroup: 1000
      initContainers:
        - name: init-directories
          image: "gitea/gitea:1.22.3-rootless"
          imagePullPolicy: IfNotPresent
          command: ["/usr/sbin/init_directory_structure.sh"]
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
          volumeMounts:
            - name: init
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
            
          securityContext:
            {}
          resources:
            limits: {}
            requests:
              cpu: 100m
              memory: 128Mi
        - name: init-app-ini
          image: "gitea/gitea:1.22.3-rootless"
          imagePullPolicy: IfNotPresent
          command: ["/usr/sbin/config_environment.sh"]
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
          volumeMounts:
            - name: config
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
            - name: inline-config-sources
              mountPath: /env-to-ini-mounts/inlines/
            
          securityContext:
            {}
          resources:
            limits: {}
            requests:
              cpu: 100m
              memory: 128Mi
        - name: configure-gitea
          image: "gitea/gitea:1.22.3-rootless"
          command: ["/usr/sbin/configure_gitea.sh"]
          imagePullPolicy: IfNotPresent
          securityContext:
            runAsUser: 1000
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
            - name: HOME
              value: /data/gitea/git
            - name: GITEA_ADMIN_USERNAME
              valueFrom:
                secretKeyRef:
                  name: user-token
                  key: username
            - name: GITEA_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: user-token
                  key: password
            - name: GITEA_ADMIN_PASSWORD_MODE
              value: keepUpdated
          volumeMounts:
            - name: init
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
            
          resources:
            limits: {}
            requests:
              cpu: 100m
              memory: 128Mi
      terminationGracePeriodSeconds: 60
      containers:
        - name: gitea
          image: "gitea/gitea:1.22.3-rootless"
          imagePullPolicy: IfNotPresent
          env:
            # SSH Port values have to be set here as well for openssh configuration
            - name: SSH_LISTEN_PORT
              value: "2222"
            - name: SSH_PORT
              value: "22"
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
            - name: TMPDIR
              value: /tmp/gitea
            - name: HOME
              value: /data/gitea/git
          ports:
            - name: ssh
              containerPort: 2222
            - name: http
              containerPort: 3000
          livenessProbe:
            failureThreshold: 10
            initialDelaySeconds: 200
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: http
            timeoutSeconds: 1
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            tcpSocket:
              port: http
            timeoutSeconds: 1
          resources:
            {}
          securityContext:
            {}
          volumeMounts:
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
            
      volumes:
        - name: init
          secret:
            secretName: gitea-init
            defaultMode: 110
        - name: config
          secret:
            secretName: gitea
            defaultMode: 110
        - name: inline-config-sources
          secret:
            secretName: gitea-inline-config
        - name: temp
          emptyDir: {}
        - name: data
          persistentVolumeClaim:
            claimName: gitea-shared-storage
---
# Source: gitea/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: gitea-postgresql
  namespace: "gitea"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.3.0
    helm.sh/chart: postgresql-15.5.20
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  serviceName: gitea-postgresql-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/instance: gitea
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: gitea-postgresql
      labels:
        app.kubernetes.io/instance: gitea
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: postgresql
        app.kubernetes.io/version: 16.3.0
        helm.sh/chart: postgresql-15.5.20
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: gitea-postgresql
      
      automountServiceAccountToken: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: gitea
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      hostNetwork: false
      hostIPC: false
      containers:
        - name: postgresql
          image: docker.io/bitnami/postgresql:16.3.0-debian-12-r23
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_USER
              value: "gitea"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: gitea-postgresql
                  key: password
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: gitea-postgresql
                  key: postgres-password
            - name: POSTGRES_DATABASE
              value: "gitea"
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "gitea" -d "dbname=gitea" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "gitea" -d "dbname=gitea" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 2Gi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
          volumeMounts:
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: empty-dir
              mountPath: /opt/bitnami/postgresql/conf
              subPath: app-conf-dir
            - name: empty-dir
              mountPath: /opt/bitnami/postgresql/tmp
              subPath: app-tmp-dir
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: empty-dir
          emptyDir: {}
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        storageClassName: ""
        volumeName: gitea-postgres
        resources:
          requests:
            storage: "10Gi"
---
# Source: gitea/charts/redis/templates/master/application.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: gitea-redis-master
  namespace: "gitea"
  labels:
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.5
    helm.sh/chart: redis-19.6.4
    app.kubernetes.io/component: master
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/instance: gitea
      app.kubernetes.io/name: redis
      app.kubernetes.io/component: master
  serviceName: gitea-redis-headless
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: gitea
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: redis
        app.kubernetes.io/version: 7.2.5
        helm.sh/chart: redis-19.6.4
        app.kubernetes.io/component: master
      annotations:
        checksum/configmap: 86bcc953bb473748a3d3dc60b7c11f34e60c93519234d4c37f42e22ada559d47
        checksum/health: aff24913d801436ea469d8d374b2ddb3ec4c43ee7ab24663d5f8ff1a1b6991a9
        checksum/scripts: 560c33ff34d845009b51830c332aa05fa211444d1877d3526d3599be7543aaa5
        checksum/secret: 1e28e5ae561812b3504142ef19d3676b5a8439e7ca16e5a6481316fd591f1fff
    spec:
      
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      serviceAccountName: gitea-redis-master
      automountServiceAccountToken: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: gitea
                    app.kubernetes.io/name: redis
                    app.kubernetes.io/component: master
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      enableServiceLinks: true
      terminationGracePeriodSeconds: 30
      containers:
        - name: redis
          image: docker.io/bitnami/redis:7.2.5-debian-12-r4
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          command:
            - /bin/bash
          args:
            - -c
            - /opt/bitnami/scripts/start-scripts/start-master.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: REDIS_REPLICATION_MODE
              value: master
            - name: ALLOW_EMPTY_PASSWORD
              value: "no"
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: gitea-redis
                  key: redis-password
            - name: REDIS_TLS_ENABLED
              value: "no"
            - name: REDIS_PORT
              value: "6379"
          ports:
            - name: redis
              containerPort: 6379
          livenessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            # One second longer than command timeout should prevent generation of zombie processes.
            timeoutSeconds: 6
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_liveness_local.sh 5
          readinessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            timeoutSeconds: 2
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_readiness_local.sh 1
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 2Gi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
          volumeMounts:
            - name: start-scripts
              mountPath: /opt/bitnami/scripts/start-scripts
            - name: health
              mountPath: /health
            - name: redis-data
              mountPath: /data
            - name: config
              mountPath: /opt/bitnami/redis/mounted-etc
            - name: empty-dir
              mountPath: /opt/bitnami/redis/etc/
              subPath: app-conf-dir
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
      volumes:
        - name: start-scripts
          configMap:
            name: gitea-redis-scripts
            defaultMode: 0755
        - name: health
          configMap:
            name: gitea-redis-health
            defaultMode: 0755
        - name: config
          configMap:
            name: gitea-redis-configuration
        - name: empty-dir
          emptyDir: {}
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: redis-data
        labels:
          app.kubernetes.io/instance: gitea
          app.kubernetes.io/name: redis
          app.kubernetes.io/component: master
      spec:
        accessModes:
          - "ReadWriteOnce"
        storageClassName: ""
        volumeName: gitea-redis
        resources:
          requests:
            storage: "8Gi"
---
# Source: gitea/templates/gitea/act_runner/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    helm.sh/chart: gitea-10.6.0
    app: gitea-act-runner
    app.kubernetes.io/name: gitea-act-runner
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/version: "1.22.3"
    version: "1.22.3"
    app.kubernetes.io/managed-by: Helm
  annotations:
  name: gitea-act-runner
  namespace: gitea
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: gitea-act-runner
      app.kubernetes.io/instance: gitea
  template:
    metadata:
      labels:
        helm.sh/chart: gitea-10.6.0
        app: gitea-act-runner
        app.kubernetes.io/name: gitea-act-runner
        app.kubernetes.io/instance: gitea
        app.kubernetes.io/version: "1.22.3"
        version: "1.22.3"
        app.kubernetes.io/managed-by: Helm
    spec:
      initContainers:
        - name: init-gitea
          image: "busybox:1.36.1"
          command:
            - sh
            - -c
            - |
              while ! nc -z gitea-http 3000; do
                sleep 5
              done
      containers:
        - name: act-runner
          image: "gitea/act_runner:0.2.11"
          imagePullPolicy: IfNotPresent
          workingDir: /data
          env:
            - name: DOCKER_HOST
              value: tcp://127.0.0.1:2376
            - name: DOCKER_TLS_VERIFY
              value: "0"
            - name: DOCKER_CERT_PATH
              value: /certs/server
            - name: GITEA_RUNNER_REGISTRATION_TOKEN
              valueFrom:
                secretKeyRef:
                  name: "gitea-actions-token"
                  key: "token"
            - name: GITEA_INSTANCE_URL
              value: http://gitea-http.gitea.svc.cluster.local:3000
            - name: CONFIG_FILE
              value: /actrunner/config.yaml
          resources:
            {}
          volumeMounts:
            - mountPath: /actrunner/config.yaml
              name: act-runner-config
              subPath: config.yaml
            - mountPath: /etc/docker/daemon.json
              name: act-runner-config
              subPath: daemon.json
            - mountPath: /certs/server
              name: docker-certs
            - mountPath: /data
              name: data-act-runner
        - name: dind
          image: "docker:25.0.2-dind"
          imagePullPolicy: IfNotPresent
          env:
            - name: DOCKER_HOST
              value: tcp://127.0.0.1:2376
            - name: DOCKER_TLS_VERIFY
              value: "0"
            - name: DOCKER_CERT_PATH
              value: /certs/server
          securityContext:
            privileged: true
          resources:
            {}
          volumeMounts:
            - mountPath: /certs/server
              name: docker-certs
            - mountPath: /etc/docker/daemon.json
              name: act-runner-config
              subPath: daemon.json
      volumes:
        - name: act-runner-config
          configMap:
            name: gitea-act-runner-config
        - name: docker-certs
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: data-act-runner
      spec:
        accessModes: [ "ReadWriteOnce" ]
        storageClassName: ""
        volumeName: gitea-act-runner
        resources:
          requests:
            storage: 1Mi
---
# Source: gitea/templates/gitea/act_runner/job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: gitea-actions-token-job
  labels:
    helm.sh/chart: gitea-10.6.0
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/version: "1.22.3"
    version: "1.22.3"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: token-job
  annotations:
  namespace: gitea
spec:
  ttlSecondsAfterFinished: 300
  template:
    metadata:
      labels:
        helm.sh/chart: gitea-10.6.0
        app: gitea
        app.kubernetes.io/name: gitea
        app.kubernetes.io/instance: gitea
        app.kubernetes.io/version: "1.22.3"
        version: "1.22.3"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: token-job
    spec:
      initContainers:
        - name: init-gitea
          image: "busybox:1.36.1"
          command:
            - sh
            - -c
            - |
              while ! nc -z gitea-http 3000; do
                sleep 5
              done
      containers:
        - name: actions-token-create
          image: "gitea/gitea:1.22.3-rootless"
          imagePullPolicy: IfNotPresent
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
          command:
            - sh
            - -c
            - |
              echo "Generating act_runner token via 'gitea actions generate-runner-token'..."
              mkdir -p /data/actions/
              gitea actions generate-runner-token | grep -E '^.{40}$' | tr -d '\n' > /data/actions/token
          resources:
            {}
          volumeMounts:
            - name: data
              mountPath: /data
        - name: actions-token-upload
          image: "bitnami/kubectl:1.29.0"
          imagePullPolicy: IfNotPresent
          env:
            - name: SECRET_NAME
              value: gitea-actions-token
          command:
            - sh
            - -c
            - |
              printf "Checking rights to update kubernetes act_runner secret..."
              kubectl auth can-i update secret/${SECRET_NAME}
              /scripts/token.sh
          resources:
            {}
          volumeMounts:
            - mountPath: /scripts
              name: scripts
              readOnly: true
            - mountPath: /data
              name: data
              readOnly: true
      restartPolicy: Never
      serviceAccount: gitea-actions-token-job
      volumes:
        - name: scripts
          configMap:
            name: gitea-scripts
            defaultMode: 0755
        - name: data
          persistentVolumeClaim:
            claimName: gitea-shared-storage
  parallelism: 1
  completions: 1
  backoffLimit: 1
---
# Source: gitea/templates/tests/test-http-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "gitea-test-connection"
  namespace: gitea
  labels:

    helm.sh/chart: gitea-10.6.0
    app: gitea
    app.kubernetes.io/name: gitea
    app.kubernetes.io/instance: gitea
    app.kubernetes.io/version: "1.22.3"
    version: "1.22.3"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test-success
spec:
  containers:
    - name: wget
      image: "busybox:latest"
      command: ['wget']
      args:  ['gitea-http:3000']
  restartPolicy: Never
